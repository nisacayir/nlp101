{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Kök Bulma (Stemming)",
      "metadata": {
        "tags": [],
        "editable": true,
        "slideshow": {
          "slide_type": ""
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Kök bulma, bir kelimenin sonundaki eklerin kaldırılarak kök formuna indirgenmesi işlemidir. Bu işlem, kelimenin farklı varyasyonlarının aynı formda temsil edilmesini sağlar. Örneğin, \"koşuyorum\", \"koşacak\" ve \"koştu\" kelimeleri \"koş\" köküne indirgenebilir.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Kullanılan Kütüphaneler :",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "- **SnowballStemmer**: Türkçe ve diğer dillerde kök bulma işlemleri için kullanılır.\n- **TurkishStemmer**: Özellikle Türkçe kök bulma için tasarlanmış bir kütüphane.\n- **NLTK**: Doğal dil işleme için temel araçlar sunar.\n\nGerekli kütüphaneleri yüklemek için aşağıdaki komutlar kullanılabilir:\n```python\n!pip install snowballstemmer\n!pip install TurkishStemmer\n!pip install nltk\n```",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Örnek 1: SnowballStemmer ile Türkçe Kök Bulma",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from snowballstemmer import TurkishStemmer\n\nturkish_words = ['yürüyorum', 'yürüyüş', 'yürüdü']\nstemmer = TurkishStemmer()\nfor word in turkish_words:\n    print(f\"{word} -> {stemmer.stemWord(word)}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Bu örnekte, SnowballStemmer kullanılarak Türkçe kelimelerin kökleri bulunuyor. Örneğin, \"yürüyorum\" kelimesi kök haline indirgenir.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Örnek 2: TurkishStemmer ile Türkçe Kök Bulma\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from TurkishStemmer import TurkishStemmer\n\nturkish_stemmer = TurkishStemmer()\nfor word in turkish_words:\n    print(f\"{word} -> {turkish_stemmer.stem(word)}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "TurkishStemmer kütüphanesi kullanılarak Türkçe kelimelerin kökleri elde edilir.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Örnek 3: PorterStemmer ile İngilizce Kök Bulma\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from nltk.stem import PorterStemmer\nfrom nltk.tokenize import word_tokenize\n\nenglish_text = \"exploring explores explored\"\nenglish_tokens = word_tokenize(english_text)\nporter_stemmer = PorterStemmer()\nporter_stemmed = [porter_stemmer.stem(word) for word in english_tokens]\nprint(english_tokens)\nprint(porter_stemmed)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "İngilizce metin üzerinde PorterStemmer kullanılarak kelimelerin kökleri bulunur.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Türkçe Metin İşleme",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom string import punctuation\n\ndef preprocess_turkish(text):\n    mystopwords = set(stopwords.words(\"turkish\"))\n    def clean_tokens(tokens):\n        return [token.lower() for token in tokens if token.lower() not in mystopwords and token not in punctuation and not token.isdigit()]\n    return clean_tokens(word_tokenize(text))\n\ndef stem_turkish_words(words):\n    return [stemmer.stemWord(word) for word in words]\n\nturkish_text = \"Büyük veri analitiği, verilerden anlam çıkarmak ve iş kararlarını desteklemek için güçlü bir araçtır. Veriler üzerinde ön işleme adımları, doğru sonuçlar elde etmek için kritik öneme sahiptir.\"\npreprocessed_turkish = preprocess_turkish(turkish_text)\nstemmed_turkish = stem_turkish_words(preprocessed_turkish)\nprint(\"İşlenmiş Türkçe Metin:\", preprocessed_turkish)\nprint(\"Köklerine Ayrılmış Türkçe Kelimeler:\", stemmed_turkish)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "1. Stopword'ler ve noktalama işaretleri kaldırılır.\n2. Geriye kalan kelimelerin kökleri bulunur.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## İngilizce Metin İşleme",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def preprocess_english(text):\n    mystopwords = set(stopwords.words(\"english\"))\n    def clean_tokens(tokens):\n        return [token.lower() for token in tokens if token.lower() not in mystopwords and token not in punctuation and not token.isdigit()]\n    return clean_tokens(word_tokenize(text))\n\ndef stem_english_words(words):\n    from nltk.stem import SnowballStemmer\n    stemmer = SnowballStemmer(\"english\")\n    return [stemmer.stem(word) for word in words]\n\nenglish_text = \"Data is a valuable resource in today's world. Analyzing big data helps organizations make informed decisions.\"\npreprocessed_english = preprocess_english(english_text)\nstemmed_english = stem_english_words(preprocessed_english)\nprint(\"Processed English Text:\", preprocessed_english)\nprint(\"Stemmed English Words:\", stemmed_english)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "# Kök Bulmanın Faydaları:",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "1. Standartlaştırma: Kök bulma işlemi, farklı çekimleri ve türevleri olan kelimeleri kök haline indirgeyerek metinlerdeki tutarlılığı artırır. Örneğin, \"koşmak\", \"koşuyor\" ve \"koşan\" gibi kelimeler \"koş\" köküne indirgenir. Bu, metin analizi sırasında kelime çeşitliliğini azaltır ve benzer anlamlı kelimelerin aynı şekilde işlenmesini sağlar.\n\n2. Arama Optimizasyonu: Kök bulma, arama motorlarının daha geniş ve doğru sonuçlar döndürmesine yardımcı olur. Örneğin, \"kitap\" kelimesini arattığınızda \"kitaplar\", \"kitabım\" gibi farklı formlar da arama sonuçlarına dahil edilir. Bu, kullanıcıların aradıkları bilgiye daha kolay ulaşmasını sağlar.\n\n3. Verimlilik Artışı: Kök bulma, metin işleme süreçlerinde hafıza kullanımını ve işlem süresini optimize eder. Kelime çeşitliliği azaldığı için, veri setleri daha küçük boyutlarda saklanabilir ve işlem hızı artar. Bu, özellikle büyük veri setleriyle çalışırken önemli bir avantaj sağlar.\n\n4. Dil Modellerinin Geliştirilmesi: Kök bulma, doğal dil işleme (NLP) modellerinin eğitimi sırasında kullanılan verilerin daha tutarlı hale gelmesini sağlar. Bu, makine öğrenimi modellerinin daha doğru ve genellenebilir sonuçlar üretmesine yardımcı olur.\n\n5. Metin Sınıflandırma ve Kümeleme: Kök bulma, metin sınıflandırma ve kümeleme gibi görevlerde performansı artırır. Benzer anlamlı kelimeler aynı köke indirgendiği için, metinler arasındaki benzerlikler daha net bir şekilde ortaya çıkar.\n\n6. Türkçe Gibi Eklemeli Diller İçin Önem: Türkçe gibi eklemeli dillerde kelimeler çok fazla çekim ve türev içerebilir. Bu nedenle, kök bulma işlemi bu dillerde daha kritik bir öneme sahiptir. Doğru kök bulma, metin analizi süreçlerinin doğruluğunu büyük ölçüde artırır.\n\n7. Hata Toleransı: Kök bulma, yazım hataları veya farklı yazım varyasyonlarına karşı daha toleranslıdır. Örneğin, \"kitab\" ve \"kitap\" gibi küçük yazım farklılıkları kök bulma ile aynı şekilde işlenebilir.\n\n8. Çok Dilli Uygulamalar: Kök bulma, çok dilli uygulamalarda metinlerin tutarlı bir şekilde işlenmesini sağlar. Farklı dillerdeki metinlerin köklerine indirgenmesi, çok dilli arama ve analiz süreçlerini kolaylaştırır.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Sonuç:",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Kök bulma (stemming), doğal dil işleme projelerinde metinlerin daha etkili bir şekilde işlenmesini sağlayan temel tekniklerden biridir. Özellikle Türkçe gibi eklemeli dillerde, doğru kök bulma işlemi büyük bir öneme sahiptir. SnowballStemmer, TurkishStemmer ve NLTK gibi araçlar, bu işlemi kolaylaştırarak metin analizi süreçlerini optimize eder. Ancak, doğru sonuçlar elde etmek için dilin yapısına uygun kütüphanelerin seçilmesi ve bu kütüphanelerin doğru şekilde kullanılması gereklidir.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Kaynaklar\nNatural Language Processing with Python (O’Reilly)\nPractical Natural Language Processing (O’Reilly)",
      "metadata": {}
    },
    {
      "cell_type": "raw",
      "source": "Bu dokümanı Jupyter Notebook olarak kaydedebilir ve GitHub'da paylaşabilirsiniz.  Her bir başlık ve kod bloğu, Jupyter'ın hücre yapısına uygun şekilde düzenlenmiştir.",
      "metadata": {
        "tags": [],
        "editable": true,
        "slideshow": {
          "slide_type": ""
        }
      }
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}